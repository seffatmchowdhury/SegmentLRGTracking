{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dc3f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from scipy.spatial.transform import Rotation as R\n",
    "import os\n",
    "import matplotlib.animation as animation\n",
    "import pandas as pd\n",
    "#from PIL import Image\n",
    "import matplotlib.image\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "#import trackeval\n",
    "\n",
    "#sequence='06'\n",
    "#series = 'MOT_300K_4S_TR_1_LITE_06_0p3'\n",
    "\n",
    "sequence='01'\n",
    "series = 'MOT_300K_4S_TR_1_LITE'\n",
    "true_fn='Z:/PHD/pcseg/TRACKS/KITTI_'+sequence+'.csv'\n",
    "trax_fn='Z:/PHD/pcseg/results/'+series+'_TRACKING_H.csv'\n",
    "\n",
    "ref = pd.read_csv(true_fn,header=None).to_numpy()\n",
    "trk = pd.read_csv(trax_fn,header=None).to_numpy()\n",
    "\n",
    "L_ref=np.unique(ref[:,0]).tolist()\n",
    "L_trk=np.unique(trk[:,0]).tolist()\n",
    "N_ref=len(L_ref)\n",
    "N_trk=len(L_trk)\n",
    "print(N_ref,N_trk,'\\n')\n",
    "print(L_ref)\n",
    "print(L_trk)\n",
    "\n",
    "NF_ref=int(np.max(ref[:,5]))\n",
    "NF_trk=int(np.max(trk[:,14]))\n",
    "\n",
    "NF=np.min([NF_ref,NF_trk])\n",
    "\n",
    "print(NF_ref,NF_trk,NF,'\\n')\n",
    "\n",
    "trk_dst=[]\n",
    "\n",
    "costm=np.zeros((N_ref,N_trk),dtype=np.float64)\n",
    "costc=np.zeros((N_ref,N_trk),dtype=np.int32)\n",
    "\n",
    "for F in range(NF):\n",
    "    ref_F=ref[ref[:,5]==F,:]\n",
    "    trk_F=trk[trk[:,14]==F,:]\n",
    "    print(F,ref_F.shape[0],trk_F.shape[0])\n",
    "    for i in range(ref_F.shape[0]):\n",
    "        for j in range(trk_F.shape[0]):\n",
    "            ii=L_ref.index(ref_F[i,0])\n",
    "            jj=L_trk.index(trk_F[j,0])\n",
    "            costm[ii,jj]+=np.linalg.norm([ref_F[i,2]-trk_F[j,8],ref_F[i,3]-trk_F[j,9],ref_F[i,4]-trk_F[j,10]])\n",
    "            costc[ii,jj]+=1\n",
    "            \n",
    "for i in range(N_ref):\n",
    "    for j in range(N_trk):\n",
    "        if costc[i,j]>0:\n",
    "            costm[i,j]/=float(costc[i,j])\n",
    "            \n",
    "for i in range(N_ref):\n",
    "    for j in range(N_trk):\n",
    "        if costm[i,j]<0.01:\n",
    "            costm[i,j]=1000000000.0\n",
    "\n",
    "row_ind, col_ind = linear_sum_assignment(costm)\n",
    "print(row_ind)\n",
    "print(col_ind)\n",
    "\n",
    "for i in range(N_ref):\n",
    "    ref_objid=L_ref[i]\n",
    "    trk_trkid=L_trk[col_ind[i]]\n",
    "    print(i,col_ind[i],ref_objid,trk_trkid,costc[i,col_ind[i]],costm[i,col_ind[i]])\n",
    "\n",
    "# Plot 1 matching set of tracks (reference and prediction)\n",
    "matchid=6 #2 #14\n",
    "\n",
    "fig2,ax2 = plt.subplots(figsize=(10, 2.5))\n",
    "figscale=1\n",
    "\n",
    "for j in range(15,16):#range(N_ref):\n",
    "    \n",
    "    plt.clf()\n",
    "\n",
    "    ref_objid=L_ref[j]\n",
    "    trk_trkid=L_trk[col_ind[j]]\n",
    "\n",
    "    ref_EX=ref[ref[:,0]==ref_objid,:]\n",
    "    NP_ref_EX=ref_EX.shape[0]\n",
    "    trk_EX=trk[trk[:,0]==trk_trkid,:]\n",
    "    NP_trk_EX=trk_EX.shape[0]\n",
    "\n",
    "    print(NP_ref_EX,NP_trk_EX)\n",
    "\n",
    "    for i in range(NP_ref_EX-1):\n",
    "        x1=ref_EX[i,3]\n",
    "        y1=ref_EX[i,4]\n",
    "        x2=ref_EX[i+1,3]\n",
    "        y2=ref_EX[i+1,4]\n",
    "        plt.plot([x1,x2], [y1,y2], '-', color=(0.9,0.1,0.1))\n",
    "    \n",
    "    for i in range(NP_trk_EX-1):\n",
    "        x1=trk_EX[i,9]\n",
    "        y1=trk_EX[i,10]\n",
    "        x2=trk_EX[i+1,9]\n",
    "        y2=trk_EX[i+1,10]\n",
    "        plt.plot([x1,x2], [y1,y2], '-', color=(0.0,0.9,0.1))\n",
    "\n",
    "    #plt.axis('equal')\n",
    "    ax = plt.gca()\n",
    "    ax.set_ylim([-3, -2])\n",
    "    plt.grid()\n",
    "    #plt.show()\n",
    "    plt.savefig('Z:/PHD/pcseg/results/'+series+'_'+str(ref_objid)+'_TRK_COMPARE_V2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bde17f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from scipy.spatial.transform import Rotation as R\n",
    "import os\n",
    "import matplotlib.animation as animation\n",
    "import pandas as pd\n",
    "#from PIL import Image\n",
    "import matplotlib.image\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import trackeval\n",
    "\n",
    "default_eval_config = trackeval.Evaluator.get_default_eval_config()\n",
    "default_eval_config['DISPLAY_LESS_PROGRESS'] = False\n",
    "default_dataset_config = trackeval.datasets.Kitti2DBox.get_default_dataset_config()\n",
    "default_metrics_config = {'METRICS': ['HOTA', 'CLEAR', 'Identity']}\n",
    "config = {**default_eval_config, **default_dataset_config, **default_metrics_config}  # Merge default configs\n",
    "\n",
    "evaluator = trackeval.Evaluator(default_eval_config)\n",
    "dataset_list = [trackeval.datasets.Kitti2DBox(default_dataset_config)]\n",
    "metrics_list = []\n",
    "for metric in [trackeval.metrics.HOTA, trackeval.metrics.CLEAR, trackeval.metrics.Identity]:\n",
    "    if metric.get_name() in default_metrics_config['METRICS']:\n",
    "        metrics_list.append(metric())\n",
    "if len(metrics_list) == 0:\n",
    "    raise Exception('No metrics selected for evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d23a95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Frames:  1101\n",
      "24739\n",
      "TR Frames:  1081\n",
      "10076\n",
      "HOTA:  5.785178284436374\n",
      "     num_frames  num_objects  num_matches      mota      motp  num_misses  \\\n",
      "acc        1081        24010         8764  0.352187  0.000109       14242   \n",
      "\n",
      "     num_false_positives  num_switches  mostly_tracked  partially_tracked  \\\n",
      "acc                  308          1004               5                100   \n",
      "\n",
      "     mostly_lost  \n",
      "acc           59  \n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from scipy.spatial.transform import Rotation as R\n",
    "import os\n",
    "import matplotlib.animation as animation\n",
    "import pandas as pd\n",
    "#from PIL import Image\n",
    "import matplotlib.image\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import trackeval\n",
    "from trackeval.datasets._base_dataset import _BaseDataset\n",
    "from trackeval.metrics._base_metric import _BaseMetric\n",
    "from trackeval.metrics.hota import HOTA\n",
    "import motmetrics as mm\n",
    "\n",
    "def Voxel_IoU(v1,v2):\n",
    "    IoU = 0\n",
    "    set1=set()\n",
    "    for i in range(v1.shape[0]):\n",
    "        voxel=(v1[i,0],v1[i,1],v1[i,2])\n",
    "        set1.add(voxel)\n",
    "    set2=set()\n",
    "    for i in range(v2.shape[0]):\n",
    "        voxel=(v2[i,0],v2[i,1],v2[i,2])\n",
    "        set2.add(voxel)\n",
    "        \n",
    "    inter = set1 & set2\n",
    "    union = set1 | set2\n",
    "    if len(union)>0:\n",
    "        IoU=len(inter)/len(union)\n",
    "    \n",
    "    return IoU\n",
    "\n",
    "def VoxelPC_TrackerMC(cloud,rr,gg,bb,resolution):\n",
    "    #cloud1 = pd.read_csv(M_fn_1,header=None).to_numpy()\n",
    "    #cloud2 = pd.read_csv(M_fn_2,header=None).to_numpy()\n",
    "    \n",
    "    npt = cloud.shape[0]\n",
    "    nc = 0\n",
    "    for i in range(npt):\n",
    "        if int(cloud[i,3])==rr and int(cloud[i,4])==gg and int(cloud[i,5])==bb:\n",
    "            nc = nc + 1\n",
    "            \n",
    "    PC = np.zeros((nc,3))\n",
    "    ni = 0\n",
    "    for i in range(npt):\n",
    "        if int(cloud[i,3])==rr and int(cloud[i,4])==gg and int(cloud[i,5])==bb:\n",
    "            PC[ni,0]=cloud[i,0]\n",
    "            PC[ni,1]=cloud[i,1]\n",
    "            PC[ni,2]=cloud[i,2]\n",
    "            ni = ni + 1\n",
    "            \n",
    "    return np.round(PC/resolution).astype(int)\n",
    "\n",
    "def VoxelPC_GTMC(cloud,objid,resolution):\n",
    "    #cloud1 = pd.read_csv(M_fn_1,header=None).to_numpy()\n",
    "    #cloud2 = pd.read_csv(M_fn_2,header=None).to_numpy()\n",
    "    \n",
    "    npt = cloud.shape[0]\n",
    "    nc = 0\n",
    "    for i in range(npt):\n",
    "        if int(cloud[i,0])==objid:\n",
    "            nc = nc + 1\n",
    "            \n",
    "    PC = np.zeros((nc,3))\n",
    "    ni = 0\n",
    "    for i in range(npt):\n",
    "        if int(cloud[i,0])==objid:\n",
    "            PC[ni,0]=cloud[i,1]\n",
    "            PC[ni,1]=cloud[i,2]\n",
    "            PC[ni,2]=cloud[i,3]\n",
    "            ni = ni + 1\n",
    "            \n",
    "    return np.round(PC/resolution).astype(int)\n",
    "\n",
    "# 6\n",
    "fn_gt = 'Z:\\PHD\\pcseg\\TRACKS\\KITTI_07_HOTA.csv'\n",
    "fn_tr = 'Z:/PHD/pcseg/results/MOT_600K_4S_TR_1_LITE_07_0p3_SEGSHOTA_NC_F.csv'\n",
    "\n",
    "# 1\n",
    "#fn_gt = 'Z:\\PHD\\pcseg\\TRACKS\\KITTI_01_HOTA.csv'\n",
    "#fn_tr = 'Z:/PHD/pcseg/results/MOT_300K_4S_TR_1_LITE_SEGSHOTA_NC.csv'\n",
    "\n",
    "acc = mm.MOTAccumulator(auto_id=True)\n",
    "\n",
    "# Load ground truth data\n",
    "read_data, ignore_data = _BaseDataset._load_simple_text_file(fn_gt, time_col=5, id_col=0)\n",
    "\n",
    "#print(read_data.keys())\n",
    "\n",
    "tot=0\n",
    "num_timesteps=len(read_data.keys())\n",
    "print('GT Frames: ',num_timesteps)\n",
    "\n",
    "data_keys = ['gt_ids', 'gt_dets']\n",
    "raw_data = {key: [None] * num_timesteps for key in data_keys}\n",
    "\n",
    "for k in read_data.keys():\n",
    "    time_data = np.asarray(read_data[k], dtype=np.float)\n",
    "    t=int(k)\n",
    "    raw_data['gt_dets'][t] = np.atleast_2d(time_data[:, 7:13])\n",
    "    raw_data['gt_ids'][t] = np.atleast_1d(time_data[:, 0]).astype(int)\n",
    "    \n",
    "    tot=tot+time_data.shape[0]\n",
    "    #print(k,t,time_data.shape,raw_data['gt_dets'][t].shape,raw_data['gt_ids'][t].shape)\n",
    "\n",
    "raw_data['gt_num_timesteps'] = num_timesteps\n",
    "raw_data['seq'] = '0006'\n",
    "print(tot)\n",
    "\n",
    "# Load tracker data\n",
    "read_data, ignore_data = _BaseDataset._load_simple_text_file(fn_tr, time_col=3, id_col=4)\n",
    "\n",
    "#print(read_data.keys())\n",
    "\n",
    "tot=0\n",
    "num_timesteps=len(read_data.keys())\n",
    "print('TR Frames: ',num_timesteps)\n",
    "\"\"\"\n",
    "for k in read_data.keys():\n",
    "    time_data = np.asarray(read_data[k], dtype=np.float)\n",
    "    print('Checking Key',k,int(k),time_data.shape)\n",
    "    print(time_data[time_data[:,3]!=int(k),3])\n",
    "\"\"\"\n",
    "    \n",
    "\n",
    "raw_data['tracker_ids'] = [None] * num_timesteps\n",
    "raw_data['tracker_dets'] = [None] * num_timesteps\n",
    "raw_data['tracker_confidences'] = [None] * num_timesteps\n",
    "raw_data['similarity_scores'] = [None] * num_timesteps\n",
    "\n",
    "for k in read_data.keys():\n",
    "    time_data = np.asarray(read_data[k], dtype=np.float)\n",
    "    t=int(k)\n",
    "    raw_data['tracker_dets'][t] = np.atleast_2d(time_data[:, 5:11])\n",
    "    raw_data['tracker_ids'][t] = np.atleast_1d(time_data[:, 4]).astype(int)\n",
    "    raw_data['tracker_confidences'][t] = np.ones(time_data.shape[0])\n",
    "    \n",
    "    tot=tot+time_data.shape[0]\n",
    "    #print(k,t,time_data.shape,raw_data['tracker_dets'][t].shape,raw_data['tracker_ids'][t].shape)\n",
    "    \n",
    "#print(read_data['195'])\n",
    "#print(len(read_data['195']))\n",
    "\n",
    "raw_data['tracker_num_timesteps'] = num_timesteps\n",
    "print(tot)\n",
    "\n",
    "total_tracked_dets = 0\n",
    "\n",
    "\n",
    "\n",
    "for k in range(num_timesteps):\n",
    "    t=str(k)\n",
    "    IOU = _BaseDataset._calculate_3d_box_ious(raw_data['gt_dets'][k],raw_data['tracker_dets'][k])\n",
    "    #print(IOU.shape)\n",
    "    raw_data['similarity_scores'][k] = IOU\n",
    "    #print(raw_data['gt_dets'][k].shape,raw_data['tracker_dets'][k].shape,raw_data['similarity_scores'][k].shape)\n",
    "    \n",
    "    acc.update(\n",
    "    raw_data['gt_ids'][k],                     # Ground truth object ID in this frame\n",
    "    raw_data['tracker_ids'][k],                # Detector hypothesis ID in this frame\n",
    "    [IOU])\n",
    "    \n",
    "    \"\"\"\n",
    "    #cloud1 = pd.read_csv('Z:/PHD/pcseg/results/lrg/MOT_300K_4S_TR_1_LITE_06_0p3/M_'+str(k)+'.csv',header=None).values\n",
    "    #cloud2 = pd.read_csv('Z:/PHD/pcseg/TRACKS/06_M/M_06_'+str(k)+'.csv',header=None).values\n",
    "    cloud1 = pd.read_csv('Z:/PHD/pcseg/results/lrg/MOT_300K_4S_TR_1_LITE/M_'+str(k)+'.csv',header=None).values\n",
    "    cloud2 = pd.read_csv('Z:/PHD/pcseg/TRACKS/01_M/M_01_'+str(k)+'.csv',header=None).values\n",
    "    N1=cloud1.shape[0]\n",
    "    N2=cloud2.shape[0]\n",
    "    \n",
    "    # Tracker\n",
    "    s1=set()\n",
    "    for i in range(N1):\n",
    "        rgb=(int(cloud1[i,3]),int(cloud1[i,4]),int(cloud1[i,5]))\n",
    "        s1.add(rgb)\n",
    "    NC1=len(s1)\n",
    "    #if k==195:\n",
    "    #    print(s1)\n",
    "    \n",
    "    total_tracked_dets = total_tracked_dets + NC1\n",
    "\n",
    "    # Ground Truth\n",
    "    s2=set()\n",
    "    for i in range(N2):\n",
    "        objid=int(cloud2[i,0])\n",
    "        s2.add(objid)\n",
    "    NC2=len(s2)\n",
    "    \n",
    "    print(NC1,NC2,raw_data['tracker_dets'][k].shape[0],raw_data['gt_dets'][k].shape[0])\n",
    "    if NC1!=raw_data['tracker_dets'][k].shape[0]:\n",
    "        print(k,' Tracker Detection Count Mismatch',NC1-raw_data['tracker_dets'][k].shape[0])\n",
    "    if NC2!=raw_data['gt_dets'][k].shape[0]:\n",
    "        print(k,' Ground Truth Detection Count Mismatch',NC2-raw_data['gt_dets'][k].shape[0])\n",
    "    \n",
    "    print(k,N1,N2,NC1,NC2)\n",
    "\n",
    "    IOU=np.zeros((NC2,NC1))\n",
    "\n",
    "    voxels1=[]\n",
    "    voxels2=[]\n",
    "\n",
    "    for ss in s1:\n",
    "        v=VoxelPC_TrackerMC(cloud1,ss[0],ss[1],ss[2],0.3)\n",
    "        voxels1.append(v)\n",
    "    \n",
    "    for ss in s2:\n",
    "        v=VoxelPC_GTMC(cloud2,ss,0.3)\n",
    "        voxels2.append(v)\n",
    "\n",
    "\n",
    "    for i in range(NC2):\n",
    "        print(i)\n",
    "        for j in range(NC1):\n",
    "            IOU[i,j]=Voxel_IoU(voxels2[i],voxels1[j])\n",
    "    \n",
    "    raw_data['similarity_scores'][k] = IOU\n",
    "    \"\"\"\n",
    "\n",
    "data_keys = ['gt_ids', 'tracker_ids', 'gt_dets', 'tracker_dets', 'tracker_confidences', 'similarity_scores']\n",
    "data = {key: [None] * raw_data['tracker_num_timesteps'] for key in data_keys}\n",
    "unique_gt_ids = []\n",
    "unique_tracker_ids = []\n",
    "num_gt_dets = 0\n",
    "num_tracker_dets = 0\n",
    "for t in range(raw_data['tracker_num_timesteps']):\n",
    "    gt_ids = raw_data['gt_ids'][t]\n",
    "    gt_dets = raw_data['gt_dets'][t]\n",
    "\n",
    "    tracker_ids = raw_data['tracker_ids'][t]\n",
    "    tracker_dets = raw_data['tracker_dets'][t]\n",
    "    tracker_confidences = raw_data['tracker_confidences'][t]\n",
    "    similarity_scores = raw_data['similarity_scores'][t]\n",
    "\n",
    "    # Match tracker and gt dets (with hungarian algorithm)\n",
    "    to_remove_matched = np.array([], np.int)\n",
    "    unmatched_indices = np.arange(tracker_ids.shape[0])\n",
    "    if gt_ids.shape[0] > 0 and tracker_ids.shape[0] > 0:\n",
    "        matching_scores = similarity_scores.copy()\n",
    "        matching_scores[matching_scores < 0.5 - np.finfo('float').eps] = 0\n",
    "        match_rows, match_cols = linear_sum_assignment(-matching_scores)\n",
    "        actually_matched_mask = matching_scores[match_rows, match_cols] > 0 + np.finfo('float').eps\n",
    "        match_rows = match_rows[actually_matched_mask]\n",
    "        match_cols = match_cols[actually_matched_mask]\n",
    "\n",
    "        unmatched_indices = np.delete(unmatched_indices, match_cols, axis=0)\n",
    "\n",
    "    unmatched_tracker_dets = tracker_dets[unmatched_indices, :]\n",
    "    to_remove_tracker = to_remove_matched\n",
    "    data['tracker_ids'][t] = np.delete(tracker_ids, to_remove_tracker, axis=0)\n",
    "    data['tracker_dets'][t] = np.delete(tracker_dets, to_remove_tracker, axis=0)\n",
    "    data['tracker_confidences'][t] = np.delete(tracker_confidences, to_remove_tracker, axis=0)\n",
    "    similarity_scores = np.delete(similarity_scores, to_remove_tracker, axis=1)\n",
    "\n",
    "    data['gt_ids'][t] = gt_ids\n",
    "    data['gt_dets'][t] = gt_dets\n",
    "    data['similarity_scores'][t] = similarity_scores\n",
    "\n",
    "    unique_gt_ids += list(np.unique(data['gt_ids'][t]))\n",
    "    unique_tracker_ids += list(np.unique(data['tracker_ids'][t]))\n",
    "    num_tracker_dets += len(data['tracker_ids'][t])\n",
    "    num_gt_dets += len(data['gt_ids'][t])\n",
    "    \n",
    "# Re-label IDs such that there are no empty IDs\n",
    "if len(unique_gt_ids) > 0:\n",
    "    unique_gt_ids = np.unique(unique_gt_ids)\n",
    "    gt_id_map = np.nan * np.ones((np.max(unique_gt_ids) + 1))\n",
    "    gt_id_map[unique_gt_ids] = np.arange(len(unique_gt_ids))\n",
    "    for t in range(raw_data['tracker_num_timesteps']):\n",
    "        if len(data['gt_ids'][t]) > 0:\n",
    "            data['gt_ids'][t] = gt_id_map[data['gt_ids'][t]].astype(np.int)\n",
    "if len(unique_tracker_ids) > 0:\n",
    "    unique_tracker_ids = np.unique(unique_tracker_ids)\n",
    "    tracker_id_map = np.nan * np.ones((np.max(unique_tracker_ids) + 1))\n",
    "    tracker_id_map[unique_tracker_ids] = np.arange(len(unique_tracker_ids))\n",
    "    for t in range(raw_data['tracker_num_timesteps']):\n",
    "        if len(data['tracker_ids'][t]) > 0:\n",
    "            data['tracker_ids'][t] = tracker_id_map[data['tracker_ids'][t]].astype(np.int)\n",
    "\n",
    "# Record overview statistics.\n",
    "data['num_tracker_dets'] = num_tracker_dets\n",
    "data['num_gt_dets'] = num_gt_dets\n",
    "data['num_tracker_ids'] = len(unique_tracker_ids)\n",
    "data['num_gt_ids'] = len(unique_gt_ids)\n",
    "data['num_timesteps'] = raw_data['tracker_num_timesteps']\n",
    "data['seq'] = raw_data['seq']\n",
    "\n",
    "\"\"\"\n",
    "for t in range(raw_data['tracker_num_timesteps']):\n",
    "    if len(data['gt_ids'][t]) > 0:\n",
    "        print('GT: ',t,data['gt_ids'][t])\n",
    "    if len(data['tracker_ids'][t]) > 0:\n",
    "        print('TR: ',t,data['tracker_ids'][t])\n",
    "\"\"\"\n",
    "\n",
    "_BaseDataset._check_unique_ids(data)\n",
    "\n",
    "hota=HOTA()\n",
    "res=HOTA.eval_sequence(hota,data)\n",
    "print('HOTA: ',np.mean(res['HOTA'])*100)\n",
    "#print(data['num_tracker_dets'])\n",
    "#print(total_tracked_dets)\n",
    "\n",
    "#res['COMBINED_SEQ'] = {}\n",
    "#HOTA.plot_single_tracker_results(res, 'MOT_300K_4S_TR_1_LITE_06_0p3', 'all', 'Z:\\PHD\\pcseg\\results\\')\n",
    "\n",
    "# Use motmetrics for MOTA\n",
    "mh = mm.metrics.create()\n",
    "report = mh.compute(acc, metrics=['num_frames', 'num_objects','num_matches' ,'mota','motp', 'num_misses','num_false_positives','num_switches','mostly_tracked','partially_tracked','mostly_lost'], name='acc')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee980efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from scipy.spatial.transform import Rotation as R\n",
    "import os\n",
    "import matplotlib.animation as animation\n",
    "import pandas as pd\n",
    "#from PIL import Image\n",
    "import matplotlib.image\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import trackeval\n",
    "from trackeval.datasets._base_dataset import _BaseDataset\n",
    "from trackeval.metrics._base_metric import _BaseMetric\n",
    "from trackeval.metrics.hota import HOTA\n",
    "\n",
    "gt=np.zeros((100,6))\n",
    "tr=np.zeros((100,6))\n",
    "\n",
    "for i in range(100):\n",
    "    gt[i,0]=1.0\n",
    "    gt[i,1]=1.0\n",
    "    gt[i,2]=1.0\n",
    "    gt[i,3]=2.0\n",
    "    gt[i,4]=2.0\n",
    "    gt[i,5]=2.0\n",
    "    \n",
    "    tr[i,0]=1.0\n",
    "    tr[i,1]=1.0\n",
    "    tr[i,2]=1.0\n",
    "    tr[i,3]=2.0\n",
    "    tr[i,4]=2.0\n",
    "    tr[i,5]=2.05\n",
    "\n",
    "\n",
    "\n",
    "scores = _BaseDataset._calculate_3d_box_ious(gt,tr)\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b338acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from scipy.spatial.transform import Rotation as R\n",
    "import os\n",
    "import matplotlib.animation as animation\n",
    "import pandas as pd\n",
    "#from PIL import Image\n",
    "import matplotlib.image\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import trackeval\n",
    "from trackeval.datasets._base_dataset import _BaseDataset\n",
    "from trackeval.metrics._base_metric import _BaseMetric\n",
    "from trackeval.metrics.hota import HOTA\n",
    "\n",
    "def Voxel_IoU(v1,v2):\n",
    "    IoU = 0\n",
    "    set1=set()\n",
    "    for i in range(v1.shape[0]):\n",
    "        voxel=(v1[i,0],v1[i,1],v1[i,2])\n",
    "        set1.add(voxel)\n",
    "    set2=set()\n",
    "    for i in range(v2.shape[0]):\n",
    "        voxel=(v2[i,0],v2[i,1],v2[i,2])\n",
    "        set2.add(voxel)\n",
    "        \n",
    "    inter = set1 & set2\n",
    "    union = set1 | set2\n",
    "    if len(union)>0:\n",
    "        IoU=len(inter)/len(union)\n",
    "    \n",
    "    return IoU\n",
    "\n",
    "def VoxelPC_TrackerMC(cloud,rr,gg,bb,resolution):\n",
    "    #cloud1 = pd.read_csv(M_fn_1,header=None).to_numpy()\n",
    "    #cloud2 = pd.read_csv(M_fn_2,header=None).to_numpy()\n",
    "    \n",
    "    npt = cloud.shape[0]\n",
    "    nc = 0\n",
    "    for i in range(npt):\n",
    "        if int(cloud[i,3])==rr and int(cloud[i,4])==gg and int(cloud[i,5])==bb:\n",
    "            nc = nc + 1\n",
    "            \n",
    "    PC = np.zeros((nc,3))\n",
    "    ni = 0\n",
    "    for i in range(npt):\n",
    "        if int(cloud[i,3])==rr and int(cloud[i,4])==gg and int(cloud[i,5])==bb:\n",
    "            PC[ni,0]=cloud[i,0]\n",
    "            PC[ni,1]=cloud[i,1]\n",
    "            PC[ni,2]=cloud[i,2]\n",
    "            ni = ni + 1\n",
    "            \n",
    "    return np.round(PC/resolution).astype(int)\n",
    "\n",
    "def VoxelPC_GTMC(cloud,objid,resolution):\n",
    "    #cloud1 = pd.read_csv(M_fn_1,header=None).to_numpy()\n",
    "    #cloud2 = pd.read_csv(M_fn_2,header=None).to_numpy()\n",
    "    \n",
    "    npt = cloud.shape[0]\n",
    "    nc = 0\n",
    "    for i in range(npt):\n",
    "        if int(cloud[i,0])==objid:\n",
    "            nc = nc + 1\n",
    "            \n",
    "    PC = np.zeros((nc,3))\n",
    "    ni = 0\n",
    "    for i in range(npt):\n",
    "        if int(cloud[i,0])==objid:\n",
    "            PC[ni,0]=cloud[i,1]\n",
    "            PC[ni,1]=cloud[i,2]\n",
    "            PC[ni,2]=cloud[i,3]\n",
    "            ni = ni + 1\n",
    "            \n",
    "    return np.round(PC/resolution).astype(int)\n",
    "\n",
    "cloud1 = pd.read_csv('Z:/PHD/pcseg/results/lrg/MOT_300K_4S_TR_1_LITE_06_0p3/M_0.csv',header=None).values\n",
    "cloud2 = pd.read_csv('Z:/PHD/pcseg/TRACKS/06_M/M_06_0.csv',header=None).values\n",
    "N1=cloud1.shape[0]\n",
    "N2=cloud2.shape[0]\n",
    "print(N1,N2)\n",
    "\n",
    "# Tracker\n",
    "s1=set()\n",
    "for i in range(N1):\n",
    "    rgb=(int(cloud1[i,3]),int(cloud1[i,4]),int(cloud1[i,5]))\n",
    "    s1.add(rgb)\n",
    "NC1=len(s1)\n",
    "\n",
    "# Ground Truth\n",
    "s2=set()\n",
    "for i in range(N2):\n",
    "    objid=int(cloud2[i,0])\n",
    "    s2.add(objid)\n",
    "NC2=len(s2)\n",
    "\n",
    "IOU=np.zeros((NC1,NC2))\n",
    "\n",
    "voxels1=[]\n",
    "voxels2=[]\n",
    "\n",
    "for ss in s1:\n",
    "    v=VoxelPC_TrackerMC(cloud1,ss[0],ss[1],ss[2],0.3)\n",
    "    voxels1.append(v)\n",
    "    \n",
    "for ss in s2:\n",
    "    v=VoxelPC_GTMC(cloud2,ss,0.3)\n",
    "    voxels2.append(v)\n",
    "\n",
    "\n",
    "for i in range(NC1):\n",
    "    print(i)\n",
    "    for j in range(NC2):\n",
    "        IOU[i,j]=Voxel_IoU(voxels1[i],voxels2[j])\n",
    "\n",
    "print(np.max(IOU),np.min(IOU),np.mean(IOU))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "331ec6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\Shared\\\\Anaconda3_64\\\\python36.zip', 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\Shared\\\\Anaconda3_64\\\\DLLs', 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\Shared\\\\Anaconda3_64\\\\lib', 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\Shared\\\\Anaconda3_64', 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\Shared\\\\Anaconda3_64\\\\lib\\\\site-packages', 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\Shared\\\\Anaconda3_64\\\\lib\\\\site-packages\\\\win32', 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\Shared\\\\Anaconda3_64\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\Shared\\\\Anaconda3_64\\\\lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\Shared\\\\Anaconda3_64\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\paperspace\\\\.ipython', 'C:\\\\Users\\\\paperspace\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\conda_env\\\\envs\\\\dcp_light_env\\\\Lib\\\\site-packages']\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "dcp = 'C:\\\\Users\\\\paperspace\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\conda_env\\\\envs\\\\dcp_light_env\\\\Lib\\site-packages'\n",
    "\n",
    "\n",
    "if dcp not in sys.path:\n",
    "    sys.path.append(dcp)\n",
    "\n",
    "print(sys.path)\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49a6156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6356b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dcp_light_env",
   "language": "python",
   "name": "dcp_light_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
